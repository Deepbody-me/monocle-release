% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/order_cells.R
\name{learnGraph}
\alias{learnGraph}
\title{Learn principal graph from the reduced space using reversed graph embedding}
\usage{
learnGraph(cds, max_components = 2, rge_method = c("SimplePPT",
  "DDRTree"), auto_param_selection = TRUE,
  partition_group = "louvain_component", do_partition = TRUE,
  scale = FALSE, close_loop = FALSE, euclidean_distance_ratio = 1,
  geodestic_distance_ratio = 1/3, prune_graph = TRUE,
  minimal_branch_len = 10, orthogonal_proj_tip = FALSE,
  verbose = FALSE, ...)
}
\arguments{
\item{cds}{the CellDataSet upon which to perform this operation}

\item{max_components}{the dimensionality of the reduced space}

\item{rge_method}{Determines how to transform expression values prior to reducing dimensionality}

\item{auto_param_selection}{when this argument is set to TRUE (default), it will automatically calculate the proper value for the ncenter (number of centroids) parameters which will be passed into DDRTree call.}

\item{partition_group}{When this argument is set to TRUE (default to be FALSE), we will learn a tree structure for each separate over-connected louvain component.}

\item{do_partition}{When this argument is set to TRUE (default to be FALSE), we will learn a tree structure for each separate over-connected louvain component.}

\item{scale}{When this argument is set to TRUE (default), it will scale each gene before running trajectory reconstruction.}

\item{close_loop}{Whether or not to perform an additional run of loop closing after running DDRTree or SimplePPT to identify potential loop structure in the data space}

\item{euclidean_distance_ratio}{The maximal ratio between the euclidean distance of two tip nodes in the spanning tree inferred from SimplePPT algorithm and 
that of the maximum distance between any connecting points on the spanning tree allowed to be connected during the loop closure procedure .}

\item{geodestic_distance_ratio}{The minimal ratio between the geodestic distance of two tip nodes in the spanning tree inferred from SimplePPT algorithm and 
that of the length of the diameter path on the spanning tree allowed to be connected during the loop closure procedure. (Both euclidean_distance_ratio and geodestic_distance_ratio 
need to be satisfied to introduce the edge for loop closure.)}

\item{prune_graph}{Whether or not to perform an additional run of graph pruning to remove small insignificant branches}

\item{minimal_branch_len}{The minimal length of the diameter path for a branch to be preserved during graph pruning procedure}

\item{orthogonal_proj_tip}{Whether to perform orthogonal projection for cells corresponding to the tip principal points. Default to be FALSE}

\item{verbose}{Whether to emit verbose output during dimensionality reduction}

\item{...}{additional arguments to pass to the dimensionality reduction function}
}
\value{
an updated CellDataSet object
}
\description{
Monocle aims to learn how cells transition through a biological program of 
gene expression changes in an experiment. Each cell can be viewed as a point 
in a high-dimensional space, where each dimension describes the expression of 
a different gene in the genome. Identifying the program of gene expression 
changes is equivalent to learning a \emph{trajectory} that the cells follow
through this space. However, the more dimensions there are in the analysis,
the harder the trajectory is to learn. Fortunately, many genes typically
co-vary with one another, and so the dimensionality of the data can be
reduced with a wide variety of different algorithms. Monocle provides two
different algorithms for dimensionality reduction via \code{reduceDimension}.
Both take a CellDataSet object and a number of dimensions allowed for the
reduced space. You can also provide a model formula indicating some variables
(e.g. batch ID or other technical factors) to "subtract" from the data so it
doesn't contribute to the trajectory.
}
\details{
You can choose two different reduction algorithms: Independent Component 
Analysis (ICA) and Discriminative Dimensionality Reduction with Trees (DDRTree).
The choice impacts numerous downstream analysis steps, including \code{\link{orderCells}}.
Choosing ICA will execute the ordering procedure described in Trapnell and Cacchiarelli et al.,
which was implemented in Monocle version 1. \code{\link[DDRTree]{DDRTree}} is a more recent manifold
learning algorithm developed by Qi Mao and colleages. It is substantially more
powerful, accurate, and robust for single-cell trajectory analysis than ICA,
and is now the default method.

Often, experiments include cells from different batches or treatments. You can
reduce the effects of these treatments by transforming the data with a linear
model prior to dimensionality reduction. To do so, provide a model formula
through \code{residualModelFormulaStr}.
}
\references{
DDRTree: Qi Mao, Li Wang, Steve Goodison, and Yijun Sun. Dimensionality reduction via graph structure learning. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 765â€“774. ACM, 2015.

L1graph (generalized SimplePPT): Qi Mao, Li Wang, Ivor Tsang, and Yijun Sun. Principal graph and structure learning based on reversed graph embedding . IEEE Trans. Pattern Anal. Mach. Intell., 5 December 2016.

Original SimplePPT: Qi Mao, Le Yang, Li Wang, Steve Goodison, Yijun Sun. SimplePPT: A Simple Principal Tree Algorithm https://epubs.siam.org/doi/10.1137/1.9781611974010.89
}
